%{
Classe responsÃ¡vel pelo objeto encarregado de representar uma rede neural
com recorrÃªncia externa global;
Atributos
h: NÃºmero de neurÃ´nios da rede;
L: NÃºmero de atrasos da rede;
nepMax: NÃºmero de Ã©pocas mÃ¡xima para a etapa de treinamento;
alfa: Taxa de aprendizagem;
A: Matriz de pesos das entradas atrasadas;
dJdA: Gradiente da matriz A;
B: Matriz de pesos das entradas externas;
dJdB: Gradiente da matriz B;
C: Matriz de pesos da camada de saÃ­da;
dJdC: Gradiente da matriz C;
Y: SaÃ­da da rede;
Yold: SaÃ­da atrasada da rede, serve como entrada interna;
%}
classdef RedeRecorrente < matlab.mixin.Copyable
	properties (SetAccess = private)
		h;
		L;
		nepMax;
		nepConvergencia;
		alfa;
		A;
		dJdA
		B;
		dJdB
		C;
		dJdC
		Yts;
		Yold;
	end
	methods
		%{
		MÃ©todo construtor da RNN
		ParÃ¢metros
		h: NÃºmero de neurÃ´nios da rede;
		L: NÃºmero de atrasos da rede;
		nepMax: NÃºmero de Ã©pocas mÃ¡xima para a etapa de treinamento;
		alfaInicial: Valor inicial para a taxa de aprendizagem;
		SaÃ­da
		rede: Objeto do tipo RedeRecorrente com os atributos inicializados
		segundo os parÃ¢metros da funÃ§Ã£o;
		%}
		function rede = RedeRecorrente(h,L,nepMax,alfaInicial)
			rede.h = h;
			rede.L = L;
			rede.nepMax = nepMax;
			rede.alfa = Alfa(alfaInicial);
		end
		%{
		FunÃ§Ã£o responsÃ¡vel pela etapa de treinamento e validaÃ§Ã£o da RNN
		ParÃ¢metros
		rede: Objeto do tipo RedeRecorrente, equivale a rede para qual serÃ¡
		feito o treinamento;
		Xtr: Conjunto de dados de entrada;
		Ydtr: SaÃ­da desejada para o conjunto Xtr;
		Xvl: Conjunto de dados de validaÃ§Ã£o;
		Ydvl: SaÃ­da desejada para Xvl;
		%}
		function treinamento(rede,Xtr,Ydtr,Xvl,Ydvl)
			nep=1;
			[Ntr,netr] = size(Xtr);
			ns = size(Ydtr,2);
			%Adiciona o bias
			Xtr = [Xtr, ones(Ntr,1)];
			%Inicializa as matrizes de pesos A, B e C
			rede.A = rands(rede.h,(ns*rede.L))/5;
			rede.B = rands(rede.h,netr+1)/5;
			rede.C = rands(ns,rede.h+1)/5;
			%Inicia Treinamento
			[rede.dJdA, rede.dJdB, rede.dJdC, rede.Yold, EQMtr(nep)] = calcGrad(rede,Xtr,Ydtr,Ntr,netr,ns);
			%Inicia a validaÃ§Ã£o
			[~,EQMvl(nep)] = calcSaida(rede,Xvl,Ydvl);
			EQMvlBest = EQMvl(nep);
			ABest = rede.A;
			BBest = rede.B;
			CBest = rede.C;
			YoldBest = rede.Yold;
			while EQMtr(nep) > 1.0e-5 && nep < rede.nepMax
				nep = nep+1;
				%Calcula o alfa
				bissecao(rede.alfa,rede,Xtr,Ydtr,Ntr,netr,ns);
				%Atualiza os pesos
				rede.A = rede.A - rede.alfa.valor*rede.dJdA;
				rede.B = rede.B - rede.alfa.valor*rede.dJdB;
				rede.C = rede.C - rede.alfa.valor*rede.dJdC;
				%Salva os gradientes passados
				%dJdAOld = rede.dJdA;
				%dJdBOld = rede.dJdB;
				%dJdCOld = rede.dJdC;
				%RecÃ¡lcula o gradiente e o EQM
				[rede.dJdA, rede.dJdB, rede.dJdC, rede.Yold, EQMtr(nep)] = calcGrad(rede,Xtr,Ydtr,Ntr,netr,ns);
				%RecÃ¡lcula o alfa pelo Ã¢ngulo
				%angulo(rede.alfa,rede,dJdAOld,dJdBOld,dJdCOld);
				%ValidaÃ§Ã£o
				[~,EQMvl(nep)] = calcSaida(rede,Xvl,Ydvl);
				if EQMvl(nep) < EQMvlBest
					ABest = rede.A;
					BBest = rede.B;
					CBest = rede.C;
					YoldBest = rede.Yold;
					rede.nepConvergencia = nep;
					EQMvlBest = EQMvl(nep);
				end
				%fprintf("EQMtr: %f\n",EQMtr(nep));
			end
			%Grava o melhor valor da validaÃ§Ã£o
			rede.A = ABest;
			rede.B = BBest;
			rede.C = CBest;
			rede.Yold = YoldBest;
			%RedeRecorrente.plotEQM(EQMtr, EQMvl);
		end
		
		%{
		FunÃ§Ã£o responsÃ¡vel pela etapa de teste da RNN
		ParÃ¢metros
		rede: Objeto do tipo RedeRecorrente equivalente a rede que serÃ¡
		testada
		Xts: Conjunto de dados de teste;
		Yts: SaÃ­da desejada para o teste;
		SaÃ­da
		EQMts: Erro quadratico mÃ©dio do teste;
		%}
		function EQMts = teste(rede,Xts,Ydts)
			[rede.Yts, EQMts] = calcSaida(rede,Xts,Ydts);
		end
		
		%Dado um valor X, prediz o próximo da série
		function Y = prediz(rede,X)
			[N,ns] = size(X);
			Y = zeros(N,1);
			X = [X, ones(N,1)];
			for t=1:N
				U = X(t,:)';
				S = rede.A*rede.Yold + rede.B*U;
				Z = tanh(S);
				Y(t,:) = rede.C*[Z;1];
				rede.Yold(2:end) = rede.Yold(1:end-1);
				rede.Yold(1:rede.L:(ns-1)*rede.L+1) = Y(t);
			end
		end
		
		%{
		FunÃ§Ã£o auxiliar utilizada no cÃ¡lculo do alfa. Atribui os valores
		dos parÃ¢metros as matrizes de pesos.
		ParÃ¢metros
		rede: Objeto do tipo RedeRecorrente para o qual as matrizes de
		pesos serÃ£o modificadas;
		A: Valor que serÃ¡ atribuÃ­do a matriz de pesos A;
		B: Valor que serÃ¡ atribuÃ­do a matriz de pesos B;
		C: Valor que serÃ¡ atribuÃ­do a matriz de pesos C;
		%}
		function setPesos(rede,A,B,C)
			rede.A = A;
			rede.B = B;
			rede.C = C;
		end
	end
	methods (Access = private)
		%{
		FunÃ§Ã£o auxiliar que cÃ¡lcula a saÃ­da da RNN
		ParÃ¢metros
		rede: Objeto do tipo RedeRecorrente equivalente a rede para qual a
		saÃ­da serÃ¡ calculada
		X: Entrada para qual a saÃ­da serÃ¡ calculada
		Yd: SaÃ­da desejada de X;
		SaÃ­das
		Y: SaÃ­da fornecida pela rede para X;
		EQM: Erro quadrÃ¡tico mÃ©dio de Y em relaÃ§Ã£o a Yd;
		%}	
		function [Y,EQM] = calcSaida(rede,X,Yd)
			[N,ns] = size(X);
			Y = zeros(N,1);
			vetErro = zeros(N,1);
			X = [X, ones(N,1)];
			for t=1:N
				U = X(t,:)';
				S = rede.A*rede.Yold + rede.B*U;
				Z = tanh(S);
				Y(t,:) = rede.C*[Z;1];
				vetErro(t) = Y(t,:)-Yd(t,:);
				rede.Yold(2:end) = rede.Yold(1:end-1);
				rede.Yold(1:rede.L:(ns-1)*rede.L+1) = Y(t);
			end
			EQM = 1/N*sum(sum(vetErro.*vetErro));%/N
		end
	end
	methods (Static = true)
		%{
		FunÃ§Ã£o auxiliar utilizada para analisar o comportamento dos EQM's
		do treinamento e da validaÃ§Ã£o por meio do plot desses valores.
		ParÃ¢mentros
		EQMtr: Erro quadrÃ¡tico mÃ©dio do treinamento;
		EQMvl: Erro quadrÃ¡tico mÃ©dio da validaÃ§Ã£o;
		%}
		function plotEQM(EQMtr, EQMvl)
			plot(EQMtr);
			hold on;
			plot(EQMvl);
			hold off;
			pause;
		end
	end
end